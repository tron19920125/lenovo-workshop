{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本教程将介绍如何使用在线端点部署机器学习模型。您将首先在本地机器上部署模型以调试任何错误，然后您将在 Azure 中部署和测试它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前置条件\n",
    "\n",
    "**要求**\n",
    "- 对机器学习有基本了解\n",
    "- 拥有具有活跃订阅的Azure账户 - [免费创建账户](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- 拥有带计算集群的Azure ML工作区 - [配置工作区](https://aka.ms/azureml-workspace-configuration)\n",
    "- Python环境\n",
    "- 已安装Azure机器学习Python SDK v2 - [安装说明](https://aka.ms/azureml-sdkv2-install) - 查看入门部分\n",
    "* 连接到AzureML工作区。在[设置SDK认证](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk)了解更多。\n",
    "* 连接到 `azureml` 系统注册表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 配置在线部署\n",
    "\n",
    "我们创建 `deployment.yml` 文件配置部署相关设置，并且部署模型\n",
    "\n",
    "\n",
    "```yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
    "name: blue\n",
    "app_insights_enabled: true\n",
    "endpoint_name: <endpoint name>\n",
    "model: \n",
    "  path: ./model/sklearn_mnist_model.pkl\n",
    "code_configuration:\n",
    "  code: ./script/\n",
    "  scoring_script: score.py\n",
    "instance_type: <instance type name>\n",
    "environment: \n",
    "  conda_file: file:./model/conda.yml\n",
    "  image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\n",
    "```\n",
    "\n",
    "参数说明：\n",
    "\n",
    "1. **基本配置参数**：\n",
    "- `$schema`: 指定配置文件的JSON模式验证地址，确保YAML格式符合Azure ML规范\n",
    "- `name`: 部署实例的名称标识符，此处设为\"blue\"\n",
    "- `endpoint_name`: 在线端点的名称，需要替换为实际的端点名称\n",
    "\n",
    "2. **监控与日志**:\n",
    "- `app_insights_enabled`: 启用Application Insights监控服务，用于收集部署性能和日志数据\n",
    "\n",
    "3. **模型配置**:\n",
    "- `model.path`: 指定训练好的模型文件路径，此处为sklearn MNIST模型的pickle文件\n",
    "\n",
    "4. **代码配置**\n",
    "- `code_configuration.code`: 包含推理代码的目录路径\n",
    "- `code_configuration.scoring_script`: 推理脚本文件名，负责模型加载和预测逻辑\n",
    "\n",
    "5. **基础设施配置**\n",
    "- `instance_type`: 部署使用的虚拟机SKU类型，需要根据性能需求选择合适规格\n",
    "- `environment.conda_file`: Conda环境依赖文件路径，定义运行环境的Python包依赖\n",
    "- `environment.image`: 基础Docker镜像，此处使用Microsoft提供的OpenMPI Ubuntu镜像\n",
    "\n",
    "下面执行部署命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml online-deployment create -f deployment.yml --all-traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 测试端点\n",
    "\n",
    "首先我们获取端点的评分 URI 和 API 密钥:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://vllm-hf-v1.eastus2.inference.ml.azure.com/v1/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer xxxxxxxxxxxxxx\"\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"prompt\": \"San Francisco is a\",\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "json_formatted_str = json.dumps(response.json(), indent=4)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 获取日志\n",
    "获取部署的日志并根据需要进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml online-deployment get-logs -n blue --endpoint vllm-hf-v1 --lines 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 删除端点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml online-endpoint delete -n vllm-hf-v1 -y"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
