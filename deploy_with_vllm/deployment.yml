$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json
name: current
endpoint_name: vllm-hf
environment_variables:
  MODEL_NAME: deepseek-ai/DeepSeek-V3-0324 # define the model name using the identifier from HG
  # VLLM_ARGS: "--enable-auto-tool-choice --tool-call-parser llama3_json"
  # HUGGING_FACE_HUB_TOKEN:  # Add your HF API key here
environment:
  image: 538c71720ea7479a897b08100da69df9.azurecr.io/azureml/azureml_a7ff7869d64bc13e3120d3acf9e66052@sha256:764ecb20ba646a223b519ff2f4f41683a8e82856289b69943863292daad1abfe
 # Replace with your own image
  inference_config:
    liveness_route:
      port: 8000
      path: /ping 
    readiness_route:
      port: 8000
      path: /health
    scoring_route:
      port: 8000
      path: /
instance_type: Standard_E4ds_v4
instance_count: 1
request_settings:
    request_timeout_ms: 60000
    max_concurrent_requests_per_instance: 16 
liveness_probe:
  initial_delay: 10
  period: 10
  timeout: 2
  success_threshold: 1
  failure_threshold: 30
readiness_probe:
  initial_delay: 120
  period: 10
  timeout: 2
  success_threshold: 1
  failure_threshold: 30