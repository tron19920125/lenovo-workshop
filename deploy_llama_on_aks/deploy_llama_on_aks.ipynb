{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de07432",
   "metadata": {},
   "source": [
    "# 在 Azure Kubernetes Service (AKS) 上使用 LLaMA-Factory Docker 部署 Llama3.1-8B 微调模型\n",
    "\n",
    "本教程将指导您使用 LLaMA-Factory Docker 镜像在 AKS 上部署微调后的模型，实现一个可扩展的模型推理服务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3e11a",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "LLaMA-Factory 是一个开源的大语言模型微调框架，提供了简单易用的工具来对 LLaMA、ChatGLM、Baichuan 等主流大模型进行高效的参数微调和训练\n",
    "\n",
    "Llama3.1-8B 是 Meta 发布的一个高效的大型语言模型\n",
    "\n",
    "Docker 是一个容器化平台，将应用程序及其依赖环境打包成轻量级、可移植的容器，实现\"一次构建，处处运行\"的部署方式。\n",
    "\n",
    "Azure Kubernetes Service (AKS) 是微软 Azure 提供的托管 Kubernetes 服务，简化了容器化应用的部署、管理和扩展，无需用户管理 Kubernetes 控制平面。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a522521",
   "metadata": {},
   "source": [
    "## 前置条件\n",
    "\n",
    "### 硬件要求\n",
    "- **CPU**: 至少 8 核心（推荐 16 核心或以上）\n",
    "- **内存**: 最少 16GB RAM（推荐 32GB 或以上）\n",
    "- **存储**: 至少 50GB 可用空间\n",
    "- **GPU**: NVIDIA GPU（至少 16GB 显存）\n",
    "\n",
    "### 软件要求\n",
    "- **操作系统**: Ubuntu 20.04/22.04 LTS 或 CentOS 7/8\n",
    "- **Python**: 3.8 或更高版本\n",
    "- **Docker**: 20.10 或更高版本\n",
    "- **CUDA**: 11.8 或更高版本（如果使用 GPU）\n",
    "\n",
    "### 系统要求\n",
    "- Azure 订阅（如果没有，请创建[免费账户](https://azure.microsoft.com/free/)）\n",
    "- Azure CLI 2.50.0 或更高版本\n",
    "- kubectl 命令行工具\n",
    "- Docker 命令行工具\n",
    "- 至少 16GB RAM 的开发机器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d472c2",
   "metadata": {},
   "source": [
    "### 安装必要工具\n",
    "\n",
    "首先，我们需要安装和配置必要的工具。以下命令将安装 Azure CLI、kubectl 和相关扩展："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa507d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装 Azure CLI (如果尚未安装)\n",
    "!curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n",
    "\n",
    "# 验证安装\n",
    "!az --version\n",
    "\n",
    "# 安装 kubectl\n",
    "!az aks install-cli\n",
    "\n",
    "# 安装 k8s-extension 扩展\n",
    "!az extension add --name k8s-extension\n",
    "\n",
    "# 更新扩展到最新版本\n",
    "!az extension update --name k8s-extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64672fcb",
   "metadata": {},
   "source": [
    "### 登录 Azure\n",
    "\n",
    "使用以下命令登录到 Azure 并设置默认订阅："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3059ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"RESOURCE_GROUP\"] = \"lenovo_vm_rg\"\n",
    "os.environ[\"LOCATION\"] = \"eastus2\"\n",
    "os.environ[\"AKS_CLUSTER_NAME\"] = \"llama-aks-cluster\"\n",
    "os.environ[\"ACR_NAME\"] = f\"llamaacr\"\n",
    "os.environ[\"NAMESPACE\"] = \"llama-inference\"\n",
    "\n",
    "# 显示配置\n",
    "print(f\"Resource Group: {os.environ['RESOURCE_GROUP']}\")\n",
    "print(f\"Location: {os.environ['LOCATION']}\")\n",
    "print(f\"AKS Cluster: {os.environ['AKS_CLUSTER_NAME']}\")\n",
    "print(f\"ACR Name: {os.environ['ACR_NAME']}\")\n",
    "print(f\"Namespace: {os.environ['NAMESPACE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e0709",
   "metadata": {},
   "source": [
    "## 创建 AKS 集群\n",
    "\n",
    "### 1. 创建资源组\n",
    "\n",
    "Azure 中的资源组是一个逻辑容器, 它允许您根据资源的生命周期和安全需求将这些资源作为一个整体进行管理。资源组中的资源可以包括虚拟机、存储账户和虚拟网络等。\n",
    "\n",
    "首先，我们需要创建一个资源组来管理所有相关资源："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建资源组\n",
    "!az group create \\\n",
    "    --name $RESOURCE_GROUP \\\n",
    "    --location $LOCATION\n",
    "\n",
    "# 验证资源组创建\n",
    "!az group show --name $RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a816f4f",
   "metadata": {},
   "source": [
    "### 2. 创建 AKS 集群\n",
    "\n",
    "创建一个适合运行 LLaMA 模型的 AKS 集群："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!az aks create \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --name $AKS_CLUSTER_NAME \\\n",
    "    --node-count 2 \\\n",
    "    --node-vm-size Standard_NC6s_v3 \\\n",
    "    --enable-managed-identity \\\n",
    "    --generate-ssh-keys \\\n",
    "    --enable-addons monitoring \\\n",
    "    --enable-cluster-autoscaler \\\n",
    "    --min-count 1 \\\n",
    "    --max-count 3 \\\n",
    "    --node-osdisk-size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b667ef1",
   "metadata": {},
   "source": [
    "参数说明：\n",
    "\n",
    "- **`--resource-group $RESOURCE_GROUP`** \n",
    "  - 指定资源组\n",
    "\n",
    "- **`--name $AKS_CLUSTER_NAME`** \n",
    "  - 指定 AKS 集群的名称\n",
    "\n",
    "- **`--node-count 2`**\n",
    "  - 设置初始节点数量为 2 个\n",
    "  - 这是集群启动时的默认节点池大小\n",
    "\n",
    "- **`--node-vm-size Standard_NC6s_v3`**\n",
    "  - 指定节点虚拟机的规格为 Standard_NC6s_v3\n",
    "  - 包含 6 个 vCPU、56 GB RAM 和 1 个 GPU\n",
    "\n",
    "- **`--node-osdisk-size 100`**\n",
    "  - 设置每个节点的操作系统磁盘大小为 100 GB\n",
    "  - 默认通常是 30 GB，100 GB 提供更多存储空间\n",
    "\n",
    "- **`--enable-managed-identity`**\n",
    "  - 启用托管身份\n",
    "  - Azure 会自动创建和管理服务主体，简化身份验证配置\n",
    "\n",
    "- **`--generate-ssh-keys`**\n",
    "  - 自动生成 SSH 密钥对\n",
    "  - 用于访问集群节点（如果需要的话）\n",
    "\n",
    "- **`--enable-addons monitoring`**\n",
    "  - 启用 Azure Monitor 容器监控\n",
    "  - 提供集群和容器的监控、日志收集功能\n",
    "\n",
    "- **`--enable-cluster-autoscaler`**\n",
    "  - 启用集群自动缩放器\n",
    "  - 根据工作负载需求自动调整节点数量\n",
    "\n",
    "- **`--min-count 1`**\n",
    "  - 设置自动缩放的最小节点数为 1\n",
    "\n",
    "- **`--max-count 3`**\n",
    "  - 设置自动缩放的最大节点数为 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f7c8e",
   "metadata": {},
   "source": [
    "\n",
    "验证集群连接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb13d79",
   "metadata": {},
   "source": [
    "返回结果包含：\n",
    "- NAME - 节点名称\n",
    "- STATUS - 节点状态（Ready/NotReady）\n",
    "- ROLES - 节点角色（master/worker）\n",
    "- AGE - 节点运行时间\n",
    "- VERSION - Kubernetes 版本\n",
    "\n",
    "返回示例：\n",
    "```shell\n",
    "NAME                                STATUS   ROLES   AGE   VERSION\n",
    "aks-nodepool1-12345678-vmss000000   Ready    agent   1h    v1.27.7\n",
    "aks-nodepool1-12345678-vmss000001   Ready    agent   1h    v1.27.7\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb799912",
   "metadata": {},
   "source": [
    "获取 AKS 凭据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az aks get-credentials \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --name $AKS_CLUSTER_NAME \\\n",
    "    --overwrite-existing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdb2c2a",
   "metadata": {},
   "source": [
    "\n",
    "参数说明：\n",
    "- **`az aks get-credentials`**\n",
    "  - Azure CLI 命令，用于下载并配置 AKS 集群的 kubeconfig 文件\n",
    "  - 配置 kubectl 以连接到指定的 AKS 集群\n",
    "\n",
    "- **`--resource-group $RESOURCE_GROUP`**\n",
    "  - 指定 AKS 集群所在的 Azure 资源组\n",
    "  - `$RESOURCE_GROUP` 是环境变量，需要与创建集群时使用的资源组一致\n",
    "\n",
    "- **`--name $AKS_CLUSTER_NAME`**\n",
    "  - 指定要获取凭据的 AKS 集群名称\n",
    "  - `$AKS_CLUSTER_NAME` 是环境变量，需要与实际的集群名称一致\n",
    "\n",
    "- **`--overwrite-existing`**\n",
    "  - 如果本地已存在同名的集群配置，则覆盖现有配置\n",
    "  - 不使用此参数时，如果存在同名配置会报错\n",
    "  - 确保获取到最新的集群凭据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9890b7ab",
   "metadata": {},
   "source": [
    "### 3. 安装 GPU 驱动程序（如果使用 GPU 节点）\n",
    "\n",
    "为 AKS 集群配置 GPU 支持："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装 NVIDIA GPU 设备插件\n",
    "!kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.14.1/nvidia-device-plugin.yml\n",
    "\n",
    "# 验证 GPU 节点\n",
    "!kubectl get nodes -o wide\n",
    "\n",
    "# 检查 GPU 资源\n",
    "!kubectl describe nodes | grep -A 5 \"Capacity\\|Allocatable\" | grep nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4740db",
   "metadata": {},
   "source": [
    "## 配置 Container Registry\n",
    "\n",
    "Azure Container Registry (ACR) 是 Azure 提供的私有 Docker 镜像仓库服务，用于存储、管理和部署容器镜像，让 AKS 等服务可以安全地拉取自定义应用镜像。\n",
    "\n",
    "### 1. 创建 Azure Container Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2534e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Azure Container Registry\n",
    "!az acr create \\\n",
    "    --name $ACR_NAME \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --location $LOCATION \\\n",
    "    --sku Standard \\\n",
    "    --admin-enabled true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef6371",
   "metadata": {},
   "source": [
    "参数说明：\n",
    "\n",
    "- **`az acr create`** - Azure CLI 命令，用于创建新的 Azure 容器注册表\n",
    "\n",
    "- **`--name $ACR_NAME`** - 指定容器注册表的名称，使用环境变量 `$ACR_NAME`，名称必须全局唯一且只能包含字母和数字\n",
    "\n",
    "- **`--resource-group $RESOURCE_GROUP`** - 指定要在其中创建 ACR 的 Azure 资源组，使用环境变量 `$RESOURCE_GROUP`\n",
    "\n",
    "- **`--location $LOCATION`** - 指定 ACR 的部署位置/区域，使用环境变量 `$LOCATION`，如 `eastus`、`westus2` 等\n",
    "\n",
    "- **`--sku Standard`** - 设置 ACR 的定价层为 Standard，提供中等性能和功能，包括 webhook、geo-replication 等功能\n",
    "\n",
    "- **`--admin-enabled true`** - 启用管理员用户账户，允许使用用户名/密码进行身份验证，便于与 Docker CLI 和其他工具集成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaed477",
   "metadata": {},
   "source": [
    "登录到ACR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!az acr login --name $ACR_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cfbbf",
   "metadata": {},
   "source": [
    "获取 ACR 登录服务器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e13505",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --resource-group $RESOURCE_GROUP --query loginServer -o tsv)\n",
    "echo \"ACR Login Server: $ACR_LOGIN_SERVER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3313a7b",
   "metadata": {},
   "source": [
    "将 ACR 与 AKS 集群关联"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa101b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!az aks update \\\n",
    "    --name $AKS_CLUSTER_NAME \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --attach-acr $ACR_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635c55e",
   "metadata": {},
   "source": [
    "### 2. 准备 LLaMA-Factory Docker 镜像\n",
    "\n",
    "我们可以直接使用官方的 LLaMA-Factory 镜像，或者自定义镜像："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db017a6",
   "metadata": {},
   "source": [
    "#### 2.1 克隆 LLaMa-Factory 仓库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 克隆 LLaMA-Factory 项目\n",
    "!git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
    "!cd LLaMA-Factory\n",
    "\n",
    "# 查看项目结构\n",
    "!ls -la LLaMA-Factory/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a4b49a",
   "metadata": {},
   "source": [
    "### 2.2 构建镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e701d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd LLaMA-Factory/docker/docker-cuda/\n",
    "\n",
    "# 构建镜像\n",
    "docker build -f ./docker/docker-cuda/Dockerfile \\\n",
    "    --build-arg PIP_INDEX=https://pypi.org/simple \\\n",
    "    --build-arg EXTRAS=metrics \\\n",
    "    -t llamafactory:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6520316",
   "metadata": {},
   "source": [
    "参数说明:\n",
    "- **`docker build`** - Docker 命令，用于构建容器镜像\n",
    "\n",
    "- **`-f ./docker/docker-cuda/Dockerfile`** - 指定构建使用的 Dockerfile 文件路径\n",
    "\n",
    "- **`--build-arg PIP_INDEX=https://pypi.org/simple`** - 设置构建参数，指定 pip 包索引源为官方 PyPI 源\n",
    "\n",
    "- **`--build-arg EXTRAS=metrics`** - 设置构建参数，指定安装额外的 metrics 功能包\n",
    "\n",
    "- **`-t llamafactory:latest`** - 为构建的镜像指定标签名称和版本，这里命名为 llamafactory，版本为 latest\n",
    "\n",
    "- **`.`** - 指定构建上下文为当前目录，Docker 会使用当前目录下的文件作为构建资源\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af90892",
   "metadata": {},
   "source": [
    "测试容器服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86928b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker compose exec llamafactory bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6510d",
   "metadata": {},
   "source": [
    "### 2.3 推送到 ACR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 获取 ACR 登录服务器地址\n",
    "ACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --resource-group $RESOURCE_GROUP --query loginServer -o tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 推送到 ACR\n",
    "!docker push ${ACR_LOGIN_SERVER}/llamafactory:latest\n",
    "\n",
    "# 验证镜像推送\n",
    "!az acr repository list --name $ACR_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918955b",
   "metadata": {},
   "source": [
    "## 创建 LLaMA-Factory 部署文件\n",
    "\n",
    "### 1. 创建 Namespace 和 ConfigMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3f9cc",
   "metadata": {},
   "source": [
    "创建配置文件目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9bb9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p k8s-manifests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b292b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建命名空间\n",
    "!kubectl create namespace $NAMESPACE\n",
    "\n",
    "# 验证命名空间创建\n",
    "!kubectl get namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86f42a",
   "metadata": {},
   "source": [
    "#### 1.1 创建 `configmap.yaml`\n",
    "\n",
    "`configmap.yaml` 是用于存储应用配置数据的配置文件，将配置信息（如环境变量、配置文件内容）从应用代码中分离出来，以键值对形式存储，供 Pod 以环境变量或挂载文件的方式使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ea909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing k8s-manifests/configmap.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile k8s-manifests/configmap.yaml\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: llama-config\n",
    "  namespace: llama-inference\n",
    "data:\n",
    "  # API 服务器监听地址，0.0.0.0 表示监听所有网络接口\n",
    "  API_HOST: \"0.0.0.0\"\n",
    "  # API 服务器监听端口，用于接收推理请求\n",
    "  API_PORT: \"8000\"\n",
    "  # Web UI 服务监听地址，0.0.0.0 表示监听所有网络接口\n",
    "  WEBUI_HOST: \"0.0.0.0\" \n",
    "  # Web UI 服务监听端口，用于访问 Web 界面\n",
    "  WEBUI_PORT: \"7860\"\n",
    "  # 要加载的模型名称，需要替换为实际使用的模型\n",
    "  MODEL_NAME: \"your-model-name\"  # 替换为您的模型名称\n",
    "  # 微调适配器路径，如果有 LoRA 等微调适配器则指定路径\n",
    "  ADAPTER_NAME: \"your-adapter-path\"  # 如果有微调适配器的话\n",
    "  # 量化位数，4 表示使用 4-bit 量化以节省内存\n",
    "  QUANTIZATION_BIT: \"4\"\n",
    "  # 对话模板类型，用于格式化输入输出\n",
    "  TEMPLATE: \"default\"\n",
    "  # Hugging Face 镜像地址，用于下载模型和数据\n",
    "  HF_ENDPOINT: \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef80a0",
   "metadata": {},
   "source": [
    "#### 1.2 创建 `deployment.yaml`\n",
    "\n",
    "`deployment.yaml` 是用于定义和管理应用部署的配置文件，描述了应用容器的运行规格、副本数量、更新策略等，Kubernetes 会根据这个文件自动创建、维护和扩展 Pod，确保应用始终按预期状态运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d647a138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing k8s-manifests/deployment.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile k8s-manifests/deployment.yaml\n",
    "# Kubernetes Deployment 资源定义\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: llama-deployment\n",
    "  namespace: llama-inference  # 部署到指定命名空间\n",
    "  labels:\n",
    "    app: llama  # 标签用于资源标识和选择器匹配\n",
    "spec:\n",
    "  replicas: 1  # 副本数量，只运行一个实例\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: llama  # 选择器，匹配具有 app=llama 标签的 Pod\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: llama  # Pod 模板标签\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: llamafactory\n",
    "        # 容器镜像，从 ACR 拉取 llamafactory 镜像\n",
    "        image: ${ACR_LOGIN_SERVER}/llamafactory:latest\n",
    "        ports:\n",
    "        - containerPort: 8000\n",
    "          name: api      # API 服务端口\n",
    "        - containerPort: 7860\n",
    "          name: webui    # Web UI 端口\n",
    "        env:\n",
    "        # 指定使用第一个 GPU 设备\n",
    "        - name: CUDA_VISIBLE_DEVICES\n",
    "          value: \"0\"\n",
    "        # Hugging Face 模型缓存目录\n",
    "        - name: HF_HOME\n",
    "          value: \"/app/models\"\n",
    "        # Hugging Face Hub 缓存目录\n",
    "        - name: HF_HUB_CACHE\n",
    "          value: \"/app/models\"\n",
    "        # 从 ConfigMap 导入环境变量\n",
    "        envFrom:\n",
    "        - configMapRef:\n",
    "            name: llama-config\n",
    "        # 容器启动命令\n",
    "        command: [\"/bin/bash\"]\n",
    "        args:\n",
    "        - -c\n",
    "        - |\n",
    "          # 启动 API 服务，后台运行\n",
    "          llamafactory-cli api \\\n",
    "            --model_name_or_path $(MODEL_NAME) \\\n",
    "            --template $(TEMPLATE) \\\n",
    "            --quantization_bit $(QUANTIZATION_BIT) \\\n",
    "            --host $(API_HOST) \\\n",
    "            --port $(API_PORT) &\n",
    "          \n",
    "          # 启动 Web UI，后台运行\n",
    "          llamafactory-cli webui \\\n",
    "            --host $(WEBUI_HOST) \\\n",
    "            --port $(WEBUI_PORT) &\n",
    "          \n",
    "          # 等待所有后台进程，保持容器运行\n",
    "          wait\n",
    "        resources:\n",
    "          requests:  # 资源请求，Pod 调度时的最小要求\n",
    "            memory: \"8Gi\"          # 请求 8GB 内存\n",
    "            cpu: \"2\"               # 请求 2 核 CPU\n",
    "            nvidia.com/gpu: 1      # 请求 1 个 GPU\n",
    "          limits:    # 资源限制，Pod 运行时的最大使用量\n",
    "            memory: \"16Gi\"         # 限制最大 16GB 内存\n",
    "            cpu: \"4\"               # 限制最大 4 核 CPU\n",
    "            nvidia.com/gpu: 1      # 限制最大 1 个 GPU\n",
    "        volumeMounts:\n",
    "        # 挂载模型缓存目录\n",
    "        - name: model-cache\n",
    "          mountPath: /app/models\n",
    "        # 挂载共享内存，用于 GPU 和进程间通信\n",
    "        - name: shm\n",
    "          mountPath: /dev/shm\n",
    "        # 就绪探针，检查容器是否准备好接收流量\n",
    "        readinessProbe:\n",
    "          httpGet:\n",
    "            path: /docs          # 检查 API 文档端点\n",
    "            port: 8000\n",
    "          initialDelaySeconds: 300  # 初始延迟 5 分钟\n",
    "          periodSeconds: 30         # 每 30 秒检查一次\n",
    "          timeoutSeconds: 10        # 超时时间 10 秒\n",
    "        # 存活探针，检查容器是否仍在运行\n",
    "        livenessProbe:\n",
    "          httpGet:\n",
    "            path: /docs          # 检查 API 文档端点\n",
    "            port: 8000\n",
    "          initialDelaySeconds: 600  # 初始延迟 10 分钟\n",
    "          periodSeconds: 60         # 每 60 秒检查一次\n",
    "          timeoutSeconds: 30        # 超时时间 30 秒\n",
    "      volumes:\n",
    "      # 模型缓存卷，用于存储下载的模型文件\n",
    "      - name: model-cache\n",
    "        emptyDir:\n",
    "          sizeLimit: 50Gi  # 限制大小为 50GB\n",
    "      # 共享内存卷，用于高性能计算\n",
    "      - name: shm\n",
    "        emptyDir:\n",
    "          medium: Memory   # 使用内存作为存储介质\n",
    "          sizeLimit: 8Gi   # 限制大小为 8GB\n",
    "      # 容忍度，允许调度到有 GPU 污点的节点\n",
    "      tolerations:\n",
    "      - key: \"sku\"\n",
    "        operator: \"Equal\"\n",
    "        value: \"gpu\"\n",
    "        effect: \"NoSchedule\"\n",
    "      # 节点选择器，只调度到有 nvidia GPU 的节点\n",
    "      nodeSelector:\n",
    "        accelerator: nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dca06c",
   "metadata": {},
   "source": [
    "#### 1.3 创建 `service.yaml`\n",
    "\n",
    "`service.yaml` 是用于定义服务网络访问的配置文件，为一组 Pod 提供稳定的网络端点和负载均衡，使得应用可以通过固定的 IP 地址和端口被访问，而无需关心底层 Pod 的动态变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fba8583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing k8s-manifests/service.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile k8s-manifests/service.yaml\n",
    "# 第一个服务：LoadBalancer 类型，对外暴露 API 和 WebUI\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: llama-service\n",
    "  namespace: llama-inference  # 部署到指定命名空间\n",
    "  labels:\n",
    "    app: llama  # 服务标签\n",
    "spec:\n",
    "  type: LoadBalancer  # 负载均衡器类型，会创建外部 IP 供外部访问\n",
    "  ports:\n",
    "  - name: api\n",
    "    port: 8000          # 外部访问端口\n",
    "    targetPort: 8000    # Pod 内部端口\n",
    "    protocol: TCP       # 协议类型\n",
    "  - name: webui\n",
    "    port: 7860          # Web UI 外部访问端口\n",
    "    targetPort: 7860    # Pod 内部 Web UI 端口\n",
    "    protocol: TCP       # 协议类型\n",
    "  selector:\n",
    "    app: llama  # 选择器，匹配 app=llama 标签的 Pod\n",
    "\n",
    "---\n",
    "# 第二个服务：ClusterIP 类型，仅集群内部访问 API 服务\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: llama-api-service\n",
    "  namespace: llama-inference  # 部署到指定命名空间\n",
    "  labels:\n",
    "    app: llama  # 服务标签\n",
    "spec:\n",
    "  type: ClusterIP  # 集群内部 IP，只能从集群内部访问\n",
    "  ports:\n",
    "  - name: api\n",
    "    port: 8000          # 集群内部访问端口\n",
    "    targetPort: 8000    # Pod 内部端口\n",
    "    protocol: TCP       # 协议类型\n",
    "  selector:\n",
    "    app: llama  # 选择器，匹配 app=llama 标签的 Pod\n",
    "\n",
    "---\n",
    "# 第三个服务：ClusterIP 类型，仅集群内部访问 Web UI 服务\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: llama-webui-service\n",
    "  namespace: llama-inference  # 部署到指定命名空间\n",
    "  labels:\n",
    "    app: llama  # 服务标签\n",
    "spec:\n",
    "  type: ClusterIP  # 集群内部 IP，只能从集群内部访问\n",
    "  ports:\n",
    "  - name: webui\n",
    "    port: 7860          # 集群内部访问端口\n",
    "    targetPort: 7860    # Pod 内部 Web UI 端口\n",
    "    protocol: TCP       # 协议类型\n",
    "  selector:\n",
    "    app: llama  # 选择器，匹配 app=llama 标签的 Pod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe085f9f",
   "metadata": {},
   "source": [
    "#### 1.4 更新 `deployment.yaml` 镜像地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --resource-group $RESOURCE_GROUP --query loginServer -o tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 替换部署文件中的镜像地址\n",
    "!sed -i \"s/\\${ACR_LOGIN_SERVER}/$ACR_LOGIN_SERVER/g\" k8s-manifests/deployment.yaml\n",
    "\n",
    "# 应用所有配置文件\n",
    "!kubectl apply -f k8s-manifests/\n",
    "\n",
    "# 检查部署状态\n",
    "!kubectl get pods -n $NAMESPACE\n",
    "!kubectl get services -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e6997",
   "metadata": {},
   "source": [
    "#### 1.5 等待服务就绪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等待 Pod 就绪\n",
    "!kubectl wait --for=condition=ready pod -l app=llama -n $NAMESPACE --timeout=600s\n",
    "\n",
    "# 查看详细状态\n",
    "!kubectl describe pods -l app=llama -n $NAMESPACE\n",
    "\n",
    "# 查看日志\n",
    "!kubectl logs -l app=llama -n $NAMESPACE --tail=50\n",
    "\n",
    "# 检查服务状态\n",
    "!kubectl get svc -n $NAMESPACE -o wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee635e84",
   "metadata": {},
   "source": [
    "获取外部IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6747cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等待外部 IP 分配\n",
    "!kubectl get service llama-service -n $NAMESPACE --watch\n",
    "\n",
    "# 获取外部 IP（这可能需要几分钟时间）\n",
    "!kubectl get service llama-service -n $NAMESPACE -o jsonpath={.status.loadBalancer.ingress[0].ip}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca655c",
   "metadata": {},
   "source": [
    "external_ip 是终端输出的外部IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试 API 健康状态\n",
    "!curl -X GET http://{external_ip}:8000/v1/models\n",
    "\n",
    "# 测试文档页面\n",
    "!curl -X GET http://{external_ip}:8000/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3351696",
   "metadata": {},
   "source": [
    "### 2. 使用 Python 测试 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a99ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# API 端点\n",
    "api_url = f\"http://{external_ip}:8000/v1/chat/completions\"\n",
    "\n",
    "# 测试数据\n",
    "test_cases = [\n",
    "    {\n",
    "        \"model\": \"microsoft/Phi-4\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"解释什么是量子计算？\"}\n",
    "        ],\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"microsoft/Phi-4\", \n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"写一个 Python 函数计算斐波那契数列\"}\n",
    "        ],\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0.5\n",
    "    }\n",
    "]\n",
    "\n",
    "# 发送测试请求\n",
    "for i, test_data in enumerate(test_cases, 1):\n",
    "    print(f\"\\n=== 测试 {i} ===\")\n",
    "    print(f\"问题: {test_data['messages'][0]['content']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            api_url,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=test_data,\n",
    "            timeout=120\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            content = result.get('choices', [{}])[0].get('message', {}).get('content', '')\n",
    "            usage = result.get('usage', {})\n",
    "            \n",
    "            print(f\"回答: {content}\")\n",
    "            print(f\"令牌使用: {usage}\")\n",
    "        else:\n",
    "            print(f\"请求失败: {response.status_code}\")\n",
    "            print(f\"错误信息: {response.text}\")\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"请求异常: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"其他错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcedb674",
   "metadata": {},
   "source": [
    "### 3. 查看日志与监控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff568c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 Pod 资源使用情况\n",
    "!kubectl top pods -n $NAMESPACE\n",
    "\n",
    "# 查看节点资源使用情况  \n",
    "!kubectl top nodes\n",
    "\n",
    "# 查看 Pod 事件\n",
    "!kubectl get events -n $NAMESPACE --sort-by='.lastTimestamp'\n",
    "\n",
    "# 实时监控日志\n",
    "!kubectl logs -f -l app=llama -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f2efc",
   "metadata": {},
   "source": [
    "## 清理资源\n",
    "\n",
    "当您完成测试后，记得清理创建的资源以避免不必要的费用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除部署\n",
    "!kubectl delete -f k8s-manifests/\n",
    "\n",
    "# 删除命名空间\n",
    "!kubectl delete namespace $NAMESPACE\n",
    "\n",
    "# 删除 ACR\n",
    "!az acr delete \\\n",
    "    --name $ACR_NAME \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --yes\n",
    "\n",
    "# 删除 AKS 集群\n",
    "!az aks delete \\\n",
    "    --name $AKS_CLUSTER_NAME \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --yes\n",
    "\n",
    "# 删除资源组（这将删除所有剩余资源）\n",
    "!az group delete \\\n",
    "    --name $RESOURCE_GROUP \\\n",
    "    --yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
